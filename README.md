IR Final Project

### Dataset 
1. Fashion-iq: https://disk.yandex.com/d/Z2E54WCwvrQA3A

reference: https://github.com/XiaoxiaoGuo/fashion-iq/issues/18

### Modify
    step 1:
    NUM_CAPTION 15 -> 5
    BLIP2_MODEL opt6.7b -> opt2.7b

step 2:
openai.api_key can't run

reference : https://github.com/yzy-bupt/SEIZE

## 20250521
### Duplicate the experiment
Run Step 1. and Step 2. as usual:
```
python src/multi_caption generator_{circo/cirr/fashioniq}.py
python src/LLM-based_editing_reasoner_{circo/cirr/fashioniq}.py
```

Step 2. will generate
```
new.cap.dress.val.json
new.cap.shirt.val.json
new.cap.toptee.val.json
```
containing the edited captions generated by an LLM. Create a new directory named `<directory_name_you_like>`, copy those jsons into
`<directory_name_you_like>/captions`, and rename them as
```
cap.dress.val.json
cap.shirt.val.json
cap.toptee.val.json
```

Then, link the `image_splits` and the `images` directory in `<directory_name_you_like>`. The final structure of the directory `<directory_name_you_like>` should be
```
<directory_name_you_like>
|-- captions
    |-- cap.dress.val.json
    |-- cap.shirt.val.json
    |-- cap.toptee.val.json
| -- image_splits
| -- images
```
The directory `FashionIQ_multi_opt_gpt35_5` is an example of such a directory. The json files in its `captions` directory are obtained by using GPT-3.5 turbo and 5 multi captions in steps 1 and 2. 

To do Step 3, run
```
./run_sem.sh
```
In the shell script, the `--dataset_path` argument should be `<directory_name_you_like>`.

